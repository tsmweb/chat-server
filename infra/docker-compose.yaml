version: "3.7"

services: 

    zookeeper:
        image: confluentinc/cp-zookeeper:latest
        container_name: zookeeper-01
        environment: 
            ZOOKEEPER_CLIENT_PORT: 2181

    kafka:
        image: confluentinc/cp-kafka:latest
        container_name: kafka-01
        depends_on:
            - zookeeper
        ports:
            - 9092:9092
            - 9094:9094
        environment:
            KAFKA_BROKER_ID: 1
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
            KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
            KAFKA_LISTENERS: INTERNAL://:9092,OUTSIDE://:9094
            KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,OUTSIDE://host.docker.internal:9094
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,OUTSIDE:PLAINTEXT
        extra_hosts:
            - "host.docker.internal:172.17.0.1"

    control-center:
        image: confluentinc/cp-enterprise-control-center:6.0.1
        container_name: control-center-01
        hostname: control-center
        depends_on:
            - kafka
        ports:
            - 9021:9021
        environment:
            CONTROL_CENTER_BOOTSTRAP_SERVERS: 'kafka:9092'
            CONTROL_CENTER_REPLICATION_FACTOR: 1
            CONTROL_CENTER_CONNECT_CLUSTER: http://kafka-connect:8087
            PORT: 9021
        extra_hosts:
            - "host.docker.internal:172.17.0.1"

    kafka-topics-generator:
        image: confluentinc/cp-kafka:latest
        depends_on:
            - kafka
        command: >
            bash -c
            "sleep 10s &&
            kafka-topics --create --topic=SERVERS --partitions 3 --if-not-exists --bootstrap-server=kafka:9092 &&
            kafka-topics --create --topic=USERS --partitions 3 --if-not-exists --bootstrap-server=kafka:9092 &&
            kafka-topics --create --topic=USERS_PRESENCE --partitions 1 --if-not-exists --bootstrap-server=kafka:9092 &&
            kafka-topics --create --topic=NEW_MESSAGES --partitions 3 --if-not-exists --bootstrap-server=kafka:9092 &&
            kafka-topics --create --topic=OFF_MESSAGES --partitions 3 --if-not-exists --bootstrap-server=kafka:9092 &&
            kafka-topics --create --topic=GROUP_EVENTS --partitions 3 --if-not-exists --bootstrap-server=kafka:9092 &&
            kafka-topics --create --topic=CONTACT_EVENTS --partitions 3 --if-not-exists --bootstrap-server=kafka:9092 &&
            kafka-topics --create --topic=H01_MESSAGES --partitions 1 --if-not-exists --bootstrap-server=kafka:9092 &&
            kafka-topics --create --topic=H02_MESSAGES --partitions 1 --if-not-exists --bootstrap-server=kafka:9092 &&
            kafka-topics --create --topic=H03_MESSAGES --partitions 1 --if-not-exists --bootstrap-server=kafka:9092 &&
            kafka-topics --create --topic=ERRORS --partitions 3 --if-not-exists --bootstrap-server=kafka:9092 &&
            kafka-topics --create --topic=METRICS --partitions 3 --if-not-exists --bootstrap-server=kafka:9092"

    kafka-connect:
        image: confluentinc/cp-kafka-connect-base:6.0.0
        container_name: kafka-connect
        depends_on:
            - zookeeper
            - kafka
        ports:
            - 8087:8087
        environment:
            CONNECT_BOOTSTRAP_SERVERS: "kafka:9092"
            CONNECT_REST_PORT: 8087
            CONNECT_GROUP_ID: kafka-connect
            CONNECT_CONFIG_STORAGE_TOPIC: _connect-configs
            CONNECT_OFFSET_STORAGE_TOPIC: _connect-offsets
            CONNECT_STATUS_STORAGE_TOPIC: _connect-status
            CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
            CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
            CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
            CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
            CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
            CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
            CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
            CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
            CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
            CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
            CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
            # # Optional settings to include to support Confluent Control Center
            #   CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
            #   CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
            #  ---------------
            CONNECT_PLUGIN_PATH: /usr/share/java,/usr/share/confluent-hub-components,/data/connect-jars
        volumes:
            - $PWD/data:/data
        command: 
            - bash
            - -c
            - |
                echo "Installing Connector"
                confluent-hub install --no-prompt confluentinc/kafka-connect-elasticsearch:10.0.1
                #
                echo "Launching Kafka Connect Worker"
                /etc/confluent/docker/run &
                #
                sleep infinity
        extra_hosts:
            - "host.docker.internal:172.17.0.1"

    es01:
        image: docker.elastic.co/elasticsearch/elasticsearch:7.11.2
        container_name: es01
        ports:
            - 9200:9200
            - 9300:9300
        environment:
            - node.name=es01
            - cluster.name=es-docker-cluster
            - cluster.initial_master_nodes=es01
            - bootstrap.memory_lock=true
            - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
        ulimits:
            memlock:
                soft: -1
                hard: -1
        volumes:
            - ./es01:/usr/share/elasticsearch/data
        extra_hosts:
            - "host.docker.internal:172.17.0.1"

    kibana:
        image: docker.elastic.co/kibana/kibana:7.11.2
        container_name: kibana-01
        ports:
            - 5601:5601
        environment:
            ELASTICSEARCH_URL: http://es01:9200
            ELASTICSEARCH_HOSTS: '["http://es01:9200"]'
        depends_on:
            - es01
        extra_hosts:
            - "host.docker.internal:172.17.0.1"